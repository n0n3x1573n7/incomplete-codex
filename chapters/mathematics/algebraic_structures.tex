\documentclass{report}

\begin{document}

	\section{Algebraic Structures}

		\subsection{Sets}

			\begin{defn}[Set] \label{def_set}
				A \emph{set} is a collection of distinct objects. 
			\end{defn}
		
			To see some traits on sets, we literally start from nothing:
			\begin{axiom}[Empty Set Axiom] \label{axiom_empty_set}
				There is a set containing no members, that is:
				\begin{displaymath}
				\exists B \text{ such that } \forall x, (x \notin B)
				\end{displaymath}
				We call this set the \emph{empty set}, and denote it by the symbol $\emptyset$.
			\end{axiom}

			We now have $\emptyset$; we now write down a few rules for how to manipulate sets.
			\begin{axiom}[Axiom of Extensionality] \label{axiom_extensionality}
				Two sets are equal if and only if they share the same elements, that is:
				\begin{displaymath}
				\forall A,B [\forall z,((z \in A) \Leftrightarrow (z \in B)) \Rightarrow (A=B)]
				\end{displaymath}
			\end{axiom}

			\begin{axiom}[Axiom of Pairing] \label{axiom_pairing}
				Given any two sets $A$ and $B$, there is a set which have the members just $A$ and $B$, that is:
				\begin{displaymath}
					\forall A,B \exists C \forall x [x \in C \Leftrightarrow ((x=A) \vee (x=B))]
				\end{displaymath}
				If $A$ and $B$ are distinct sets, we write this set $C$ as $\{A,B\}$; if $A=B$, we write it as $\{A\}$.
			\end{axiom}
	
			\begin{axiom}[Axiom of Union, simple version] \label{axiom_union_simple}
				Given any two sets $A$ and $B$, there is a set whose members are those sets belonging to either $A$ or $B$, that is:
				\begin{displaymath}
					\forall A,B \exists C \forall x [x \in C \Leftrightarrow ((x \in A) \vee (x \in B))]
				\end{displaymath}
				We write this set $C$ as $A \cup B$.
			\end{axiom}
			
			In the simplified version of Axiom of Union, we take union of only two things, but we sometimes we want to take unions of more than two things or even more than finitely many things. This is given by the full version of the axiom:
		
			\begin{axiom}[Axiom of Union, full version] \label{axiom_union_full}
				Given any set $A$, there is a set $C$ whose elements are exactly the members of the members of $A$, that is:
				\begin{displaymath}
					\forall A \exists C [x \in C \Leftrightarrow (\exists A'(A' \in A) \wedge (x \in A'))]
				\end{displaymath}
				We denote this set $C$ as
				\begin{displaymath}
					\bigcup_{A' \in A}A'
				\end{displaymath}
			\end{axiom}

			\begin{axiom}[Axiom of Intersection, simple version] \label{axiom_intersection_simple}
				Given any two sets $A$ and $B$, there is a set whose members are member of both $A$ and $B$, that is:
				\begin{displaymath}
					\forall A,B \exists C \forall x [(x \in C) \Leftrightarrow ((x \in A ) \wedge (x \in B))]
				\end{displaymath}
			\end{axiom}
	
			Sometimes as union, we would want to take intersection of more than finitely many things. This is given by the full version of the axiom:
			
			\begin{axiom}[Axiom of Intersection, full version] \label{axiom_intersection_full}
				Given any set $A$, there is a set $C$ whose elements are exactly the members of all members of $A$, that is:
				\begin{displaymath}
					\forall A \exists C \forall x [(x \in C) \Leftrightarrow (\forall A'((A' \in A) \Rightarrow (x \in A')))]
				\end{displaymath}
				We denote this set $C$ as
				\begin{displaymath}
					\bigcap_{A' \in A}A'
				\end{displaymath}
			\end{axiom}
		
			\begin{axiom}[Axiom of Subset] \label{axiom_subset}
				For any two sets $A$ and $B$, we say that $B \subset A$ if and only if every member of B is a member of A, that is:
				\begin{displaymath}
					(B \subseteq A) \Leftrightarrow (\forall x (x \in B) \Rightarrow (x \in A))
				\end{displaymath}
			\end{axiom}
			
			By the Axiom of Subset we can define the power set of an any given set:
			
			\begin{defn}[Power Set] \label{def_powerset}
				For any set $A$, the \emph{power set} of the set $A$, denoted $P(A)$, whose members are precisely the collection of all possible subsets of A, that is:
				\begin{displaymath}
					\forall A \exists P(A) \forall B((B \subseteq A) \Leftrightarrow (B \in P(A)))
				\end{displaymath}
			\end{defn}
		
			\begin{defn}[Equivalence Relation] \label{def_equiv_rel}
				Let $S$ be a set. An \emph{Equivalence Relation} on $S$ is a relation, denoted by $\textasciitilde$, with the following properties, $\forall a,b,c \in S$:
				\begin{itemize}
					\item \textbf{Reflexivity} $a\textasciitilde a$
					\item \textbf{Symmetry} $a\textasciitilde b \Leftrightarrow b\textasciitilde a$
					\item \textbf{Transitivity} $(a\textasciitilde b) \wedge (b\textasciitilde c) \Rightarrow (a\textasciitilde c)$
				\end{itemize}
			\end{defn}
		
			\begin{defn}[Setoid] \label{def_setoid}
				A \emph{setoid} is a set in which an equivalence relation is defined, denoted $(S,\textasciitilde )$.
			\end{defn}
	
			\begin{defn}[Equivalence Class] \label{def_equivalence_class}
				The equivalence class of $a\in S$ under $\textasciitilde $, denoted $[a]$, is defined as $[a]=\{b \in S|a \textasciitilde b\}$.
			\end{defn}

			\begin{defn}[Order] \label{def_order}
				Let $S$ be a set. An \emph{order} on $S$ is a relation, denoted by $<$, with the following properties:
				\begin{itemize}
					\item If $x \in S$ and $y \in S$ then one and only one of the following statements is true:
					\begin{displaymath}
						x<y, x=y, y<x
					\end{displaymath}
					\item For $x,y,z \in S$, if $x<y$ and $y<z$, then $x<z$.
				\end{itemize}
			\end{defn}

			\begin{remark} \label{remark_order}
				\begin{itemize}
					\item[]
					\item It is possible to write $x>y$ in place of $y<x$
					\item The notation $x \leq y$ indicates that $x<y$ or $x=y$.
				\end{itemize}
			\end{remark}

		\begin{defn}[Ordered Set] \label{def_ordered_set}
			An \emph{ordered set} is a set in which an order is defined, denoted $(S,<)$.
		\end{defn}

		\begin{defn}[Bound] \label{def_bound}
			Suppose $S$ is an ordered set, and $E\subset S$.\\
			If there exists $\beta \in S$ such that $x \leq \beta$ for every $x \in E$, we say that E is \emph{bounded above}, and call $\beta$ an \emph{upper bound} of E.
			If there exists $\alpha \in S$ such that $x \geq \alpha$ for every $x \in E$, we say that E is \emph{bounded below}, and call $\alpha$ a \emph{lower bound} of E.
		\end{defn}

		\begin{defn}[Least Upper Bound] \label{def_supremum}
			Suppose that $S$ is an ordered set, and $E \subset S$.
			If there exists a $\beta \in S$ with the following properties:
			\begin{itemize}
				\item $\beta$ is an upper bound of $E$
				\item If $\gamma < \beta$, then $\gamma$ is not an upper bound of E
			\end{itemize}
			Then $\beta$ is called the \emph{Least Upper Bound} of E or the \emph{supremum} of E, denoted
			\begin{displaymath}
				\beta=sup(E)
			\end{displaymath}
		\end{defn}

		\begin{defn}[Greatest Lower Bound] \label{def_infimum}
			Suppose that $S$ is an ordered set, and $E \subset S$.
			If there exists a $\alpha \in S$ with the following properties:
			\begin{itemize}
				\item $\alpha$ is a lower bound of $E$
				\item If $\gamma < \alpha$, then $\gamma$ is not an lower bound of E
			\end{itemize}
			Then $\alpha$ is called the \emph{Greatest Lower Bound} of E or the \emph{infimum} of E, denoted
			\begin{displaymath}
			\beta=inf(E)
			\end{displaymath}
		\end{defn}

		\begin{defn}[least-upper-bound property] \label{def_least_upper_bound_property}
			An ordered set $S$ is said to have the \emph{least-upper-bound property} if the following is true:\\
			if $E \subset S$, $E$ is not empty, and $E$ is bounded above, then $sup(E)$ exists in $S$.
		\end{defn}

		\begin{defn}[greatest-lower-bound property] \label{def_greatest_lower_bound_property}
			An ordered set $S$ is said to have the \emph{greatest-lower-bound property} if the following is true:\\
			if $E \subset S$, $E$ is not empty, and $E$ is bounded below, then $inf(E)$ exists in $S$.
		\end{defn}

		\begin{thm} \label{thm_glb_lub_property}
			Suppose $S$ is an ordered set with the least-upper-bound property, $B \subset S$, $B$ is not empty, and $B$ is bounded below.\\
			Let $L$ be the set of all lower bounds of $B$. Then
			\begin{displaymath}
				\alpha=sup(L)
			\end{displaymath}
			exists in $S$, and $\alpha=inf(B)$.
		\end{thm}

		\begin{proof}
			Note that $\forall x \in L, y \in B, x \leq y$.\\
			$L$ is nonempty as $B$ is bounded below.\\
			$L$ is bounded above since $\forall x \in S \backslash L, \forall y \in L, x>y$.\\
			Since $S$ has the least-upper-bound property and $L \subset S$, $\exists \alpha=sup(L)$.\\
			The followings hold:
			\begin{itemize}
				\item $\alpha$ is a lower bound of $B$.
					\\($\because$) $\forall \gamma \in B, \gamma > \alpha$
				\item $\beta$ with $\beta > \alpha$ is not a lower bound of $B$
					\\($\because$)Since $\alpha$ is an upper bound of $L$, $\beta \notin L$.
			\end{itemize}
			Hence $\alpha=inf(B)$.
		\end{proof}
		
		\begin{coro} \label{coro_glb_lub_property_equiv}
			For all ordered sets, the Least Upper Bound property and the Greatest Lower Bound Porperty are equivalent.
		\end{coro}

		\subsection{Group}

			\begin{defn}[Group] \label{def_group}
				A \emph{group} is a set $G$ with a binary operation $\cdot$, denoted $(G,\cdot)$, which satisfies the following conditions:
				\begin{itemize}
					\item \textbf{Closure}: $\forall a,b \in G, a \cdot b \in G$
					\item \textbf{Associativity}: $\forall a,b,c \in G, (a \cdot b) \cdot c=a \cdot (b \cdot c)$
					\item \textbf{Identity}: $\exists e \in G, \forall a \in G, a \cdot e=e \cdot a=a$
					\item \textbf{Inverse}: $\forall a \in G, \exists a^{-1} \in G, a \cdot a^{-1}=a^{-1} \cdot a=e$
				\end{itemize}
			\end{defn}

		\begin{defn}[Semigroup] \label{def_semigroup}
			A \emph{semigroup} is $(G,\cdot)$, which satisfies Closure and Associativity.
		\end{defn}

		\begin{defn}[Monoid] \label{def_monoid}
			A \emph{monoid} is a semigroup $(G,\cdot)$ which also has identity.
		\end{defn}

		\begin{defn}[Abelian Group] \label{def_abelian_group}
			An \emph{Abelian Group} or \emph{Commutative Group} is a group $(G,\cdot)$ with the following property:
			\begin{itemize}
				\item \textbf{Commutativity}: $\forall a,b \in G, a \cdot b=b \cdot a$
			\end{itemize}
		\end{defn}

		\subsection{Ring}

			\begin{defn}[Ring] \label{def_ring}
				A \emph{Ring} is a set $R$ with two binary operations $+$ and $\cdot$, often called the addition and multiplication of the ring, denoted $(R,+,\cdot)$, which satisfies the following conditions:
				\begin{itemize}
					\item $(R,+)$ is an abelian group
					\item $(R,\cdot)$ is a semigroup
					\item \textbf{Distribution}: $\cdot$ is distributive with respect to $+$, that is, $\forall a,b,c \in R$:
					\begin{itemize}[label=-]
						\item $a \cdot (b + c)=(a \cdot b) + (a \cdot c)$
						\item $(a + b) \cdot c=(a \cdot c) + (b \cdot c)$
					\end{itemize}
				\end{itemize}
			The identity element of $+$ is often noted $0$.
			\end{defn}

		\begin{defn}[Ring with identity(1)] \label{def_ring_with_1}
			A \emph{Ring with identity} is a ring $(R,+,\cdot)$ of which $(R,\cdot)$ is a monoid. The identity element of $\cdot$ is often noted $1$.
		\end{defn}

		\begin{defn}[Commutative Ring] \label{def_commutative_ring}
			A \emph{commutative ring} is a ring $(R,+,\cdot)$ of which $\cdot$ is commutative.
		\end{defn}

		\begin{defn}[Zero Divisor] \label{def_zero_divisor}
			For a ring $(R,+,\cdot)$, let $0$ be the identity of $+$.\\
			$a,b\in R$, $a \neq 0$ and $b \neq 0$, if $a \cdot b=0$, $a,b$ are called the zero divisors of the ring.
		\end{defn}

		\begin{defn}[Integral Domain] \label{def_integral_domain}
			An \emph{integral domain} is a commutative ring $(R,+,\cdot)$ with 1 which does not have zero divisors.
		\end{defn}

		\subsection{Field}

		\begin{defn}[Field] \label{def_field}
			A \emph{Field} is a set $F$ with two binary operations $+$ and $\cdot$, often called the addition and multiplication of the field, denoted $(R,+,\cdot)$, which satisfies the following conditions:
			\begin{itemize}
				\item $(F,+,\cdot)$ is a ring
				\item $(F\backslash \{0\},\cdot)$ is a group
			\end{itemize}
			Alternatively, a Field may be defined with a set of \emph{Field Axioms} listed below:
			\begin{itemize}
					\item[(A)] \textbf{Axioms for Addition}
					\begin{itemize}
						\item[(A1)] \textbf{Closed under Addition}\\$\forall a,b \in F, a+b \in F$
						\item[(A2)] \textbf{Addition is Commutative}\\$\forall a,b \in F, a+b=b+a$
						\item[(A3)] \textbf{Addition is Associative}\\$\forall a,b,c \in F, (a+b)+c=a+(b+c)$
						\item[(A4)] \textbf{Identity of Addition}\\$\exists 0 \in F, \forall a \in F, 0+a=a$
						\item[(A5)] \textbf{Inverse of Addition}\\$\forall a \in F, \exists -a \in F, a+(-a)=0$
					\end{itemize}
					\item[(M)] \textbf{Axioms for Multiplication}
					\begin{itemize}
						\item[(M1)] \textbf{Closed under Multiplication}\\$\forall a,b \in F, a \cdot b \in F$
						\item[(M2)] \textbf{Multiplication is Commutative}\\$\forall a,b \in F, a \cdot b=b \cdot a$
						\item[(M3)] \textbf{Multiplication is Associative}\\$\forall a,b,c \in F, (a \cdot b) \cdot c=a \cdot (b \cdot c)$
						\item[(M4)] \textbf{Identity of Multiplication}\\$\exists 1 \in F, \forall a \in F, 1 \cdot a=a$
						\item[(M5)] \textbf{Inverse of Multiplication}\\$\forall a \in F\backslash\{0\}, \exists a^{-1} \in F, a \cdot a^{-1}=1$
					\end{itemize}
				\item[(D)] \textbf{Distributive Law}
				\\$\forall a,b,c \in F, (a+b) \cdot c=a \cdot c+b \cdot c$\\where $\cdot$ takes precedence over $+$.
			\end{itemize}
		\end{defn}
		
		\begin{thm}
			Let $F$ be a field. Let $0$ be the additive identity of $F$. Then, $\forall a \in F, 0 \cdot a = 0$
		\end{thm}
		
		\begin{defn}[Ordered Field] \label{def_ordered_field}
			An \emph{ordered field} is a field $F$ which is an ordered set, such that the order is compatible with the field operations, that is:
			\begin{itemize}
				\item $x+y<x+z$ if $x,y,z \in F$ and $y<z$
				\item $xy>0$ if $x,y \in F$, $x>0$ and $y>0$
			\end{itemize}
			\end{defn}
	
		\subsection{Polynomial Ring}
		\begin{defn}[Polynomial over a Ring] \label{def_polynomial}
			A polynomial $f(x)$ over the ring $(R,+,\cdot)$ is defined as
			\begin{displaymath}
				f(x)=\sum_{i=0}^{\infty}a_ix^i=a_0+a_1x^1+\cdots,a_i\in R
			\end{displaymath}
			where $a_i=0$ for all but finitely many values of $i$.\\
			The \emph{degree} of the polynomial $\deg(f)$ is defined as $\deg(f)=\max\{n|n\in\mathbb{N}, a_n\ne0 \}$.
			The \emph{leading coefficient} of the polynomial is defined as $a_{\deg(f)}$.
		\end{defn}

		\begin{defn}[Addition and Multiplication of Polynomials] \label{def_add_mult_polynomial}
			Let $f(x)=\sum_{i=0}^{\infty}a_ix^i$, $g(x)=\sum_{i=0}^{\infty}b_ix^i$, $a_i,b_i \in R$ be a polynomial over the ring $(R,+,\cdot)$. Define:
			\begin{gather*}
				f(x)+g(x)=\sum_{i=0}^{\infty}(a_i+b_i)x^i\\
				f(x)g(x)=\sum_{k=0}^{\infty}(c_k)x^k \text{ where } c_k=\sum_{i+j=k}a_ib_j
			\end{gather*}
		\end{defn}

		\begin{defn}[Polynomial Ring] \label{def_polynomial_ring}
			The set of polynomials over the ring $(R,+,\cdot)$, $R[x]=\{f(x)|f(x) \text{ is a polynomial over } R \}$ is called the \emph{Polynomial Ring(or Polynomials) over $R$}.
		\end{defn}

		\begin{thm}[Degree of Polynomial on Addition and Multiplication] \label{thm_add_mult_deg}
			Let $f(x),g(x) \in R[x]$ with $\deg(f)=n$, $\deg(g)=m$.
			\begin{itemize}
				\item $0 \le \deg(f+g) \le \max(\deg(f),\deg(g))$
				\item $\deg(fg) \le \deg(f)+\deg(g)$.
				\subitem If $(R,+,\cdot)$ is an integral domain, $\deg(fg) = \deg(f)+\deg(g)$
			\end{itemize}
		\end{thm}

		\begin{thm}[Relationship between a Ring and its Polynomial Ring] \label{thm_ring_polynomial_relationship}
			Let $(R,+,\cdot)$ be a ring and $R[x]$ the polynomials over $R$.
			\begin{enumerate}
				\item If $(R,+,\cdot)$ is a commutative ring with $1$, then $(R[x],+,\cdot)$ is a commutative ring with $1$.
				\item If $(R,+,\cdot)$ is a integral domain, then $(R[x],+,\cdot)$ is a integral domain.
			\end{enumerate}
		\end{thm}

		\begin{thm}[Division Algorithm for Polynomials over a Ring] \label{thm_polynomial_division_algorithm_ring}
			Let $(R,+,\cdot)$ be a commutative ring with $1$.\\
			Let $f(x),g(x) \in R[x]$, $g(x) \ne 0$ with the leading coefficient of $g(x)$ being invertible.\\
			Then, $\exists! q(x),r(x) \in R[x]$ such that
			\begin{displaymath}
				f(x)=q(x)g(x)+r(x)
			\end{displaymath}
			where either $r(x)=0$ or $\deg(r)<\deg(g)$.
		\end{thm}

		\begin{proof}
				Use induction on $\deg(f)$.\\
				1. $f(x)=0$ or $\deg(f)<\deg(g)$: $q(x)=0, r(x)=f(x)$\\
				2. $\deg(f)=\deg(g)=0$: $q(x)=f(x) \cdot g(x)^{-1}, r(x)=0$\\
				3. $\deg(f)\ge\deg(g)$:\\
				
				1) Existence\\
				Let $\deg(f)=n$, $\deg(g)=m$, $n>m$.\\
				Suppose the theorem holds for $\deg(f)<n$.\\
				Let $f(x)=a_0+a_1x^1+\cdots+a_nx^n$, $g(x)=b_0+b_1x^1+\cdots+b_mx^m$.\\
				Choose $f_1(x)=f(x)-(a_nb_m^{-1})x^{n-m}g(x)\in R[x]$.\\
				Since $\deg(f_1)<n$, $\exists q(x),r(x)\in R[x]$ so that $f_1(x)=g(x)q(x)+r(x)$, where $r(x)=0$ or $\deg(r)<\deg(g)$.\\
				$f_1(x)=f(x)-(a_nb_m^{-1})x^{n-m}g(x)=g(x)q(x)+r(x)$\\
				$f(x)=g(x)((a_nb_m^{-1})x^{n-m}+q(x))+r(x)$\\
				Hence such pair exists.\\
				
				2) Uniqueness\\
				Suppose $f(x)=g(x)q_1(x)+r_1(x)=g(x)q_2(x)+r_2(x)$.\\
				$g(x)(q_1(x)-q_2(x))=r_2(x)-r_1(x)$\\
				If $r_1 \ne r_2$, $\deg(g)>\deg(r_2-r_1)=\deg(g(q_1-q_2))$.\\
				Since $\deg(g(q_1-q_2))\ge\deg(g)$ if $q_1-q_2\ne0$, $q_1=q_2$, but if so, $r_1=r_2$.\\
				If $r_1=r_2$, trivially $q_1=q_2$.\\
				Hence they exist uniquely.
		\end{proof}
		
		\subsection{Vector Space}\label{chap_vector_space}
		\begin{defn}[Vector Space]
			A \emph{vector space} over a field $F$ is a set $V$ together with two operations, addition($+:V\times V \rightarrow V$) and scalar multiplication($\cdot:F \times V \rightarrow V$), satisfying the following axioms:
			\begin{itemize}
				\item[(A)] \textbf{Axioms for Addition}
				\begin{itemize}
					\item[(A1)] \textbf{Closed under Addition}\\$\forall \vec{u} ,\vec{v} \in V, \vec{u}+\vec{v} \in V$
					\item[(A2)] \textbf{Addition is Commutative}\\$\forall \vec{u}, \vec{v} \in V, \vec{u}+\vec{v}=\vec{v}+\vec{u}$
					\item[(A3)] \textbf{Addition is Associative}\\$\forall \vec{u},\vec{v},\vec{w} \in v, (\vec{u}+\vec{v})+\vec{w}=\vec{u}+(\vec{v}+\vec{w})$
					\item[(A4)] \textbf{Identity of Addition(Zero vector)}\\$\exists \vec{0} \in V, \forall \vec{u} \in F, \vec{0}+\vec{u}=\vec{u}+\vec{0}=\vec{u}$
					\item[(A5)] \textbf{Inverse of Addition(Negative)}\\$\forall \vec{u} \in V, \exists -\vec{u} \in V, \vec{u}+(-\vec{u})=0$
				\end{itemize}
				\item[(M)] \textbf{Axioms for Scalar Multiplication}
				\begin{itemize}
					\item[(M1)] \textbf{Closed under Scalar Multiplication}\\$\forall k \in F, \vec{u} \in V, k \cdot \vec{u} \in V$
					\item[(M2)] \textbf{Scalar Multiplication is Distributive(1)}\\$\forall k \in F, \vec{u}, \vec{v} \in V, k \cdot (\vec{u}+\vec{v})=k \cdot \vec{u} + k \cdot \vec{v}$
					\item[(M3)] \textbf{Scalar Multiplication is Distributive(2)}\\$\forall k, m \in F, \vec{u} \in V, (k+m) \cdot \vec{u}=k \cdot \vec{u} + m \cdot \vec{u}$
					\item[(M4)] \textbf{Scalar Multiplication is Associative}\\$\forall k, m \in F, \vec{u} \in V, (km) \cdot \vec{u}=k \cdot (m \cdot \vec{u})$
					\item[(M5)] \textbf{Identity of Scalar Multiplication}\\$\exists 1 \in F, \forall \vec{u} \in V, 1 \cdot \vec{u}=\vec{u}$
				\end{itemize}
			\end{itemize}
		\end{defn}
	
		\begin{thm}
			Let $V$ be a vector space over a field $F$. $\vec{u} \in V$, $k \in F$, $0$ the additive identity of $F$, $1$ the multiplicative identity of $F$, $\vec{0}$ the additive identity of $V$. Then, the followings hold:
			\begin{itemize}
				\item $0 \cdot \vec{u} = \vec{0}$
				\item $k \cdot \vec{0} = \vec{0}$
				\item $-1 \cdot \vec{u} = -\vec{u}$
				\item If $k \cdot \vec{u} = \vec{0}$, then $k=0$ or $\vec{u}=\vec{0}$.
			\end{itemize}
		\end{thm}
		
		\begin{defn}[Subspace of a Vector Space]
			A subset $W$ of a vector space $V$ is called a \emph{subspace} of $V$ if $W$ is a vector space under the addition and scalar multiplication defined on $V$.
		\end{defn}

		\begin{thm}
			If $W$ is a set of one or more vectors in a vector space $V$ over the field $F$, then $W$ is a subspace of $V$ iff the following conditions hold:
			\begin{itemize}
				\item $\forall \vec{u}, \vec{v} \in W, \vec{u}+\vec{v} \in W$
				\item $\forall k \in F, \vec{u} \in W, k \cdot \vec{u} \in W$
			\end{itemize}
		\end{thm}
	
		\begin{thm}
			If $W_1, W_2, \dots , W_r$ are subspaces of a vector space $V$, then $\cap_{i=1}^{r}W_i$ is also a subspace of $V$.
		\end{thm}
	
		\begin{defn}[Linear Combination]
			If $\vec{w}$ is a vector in a vector space $V$ over the field $F$, then $\vec{w}$ is said to be a \emph{Linear Combination} of the vectors $\vec{v_1}, \vec{v_2}, \dots, \vec{v_r} \in V$ if $\vec{w}$ can be expressed in the form $\vec{w}=\sum_{i=1}^{r}k_i\vec{v_i}$, where $k_1, k_2, \dots, k_r \in F$. These scalars are called the \emph{coefficients} of the linear combination.
		\end{defn}
	
		\begin{defn}[Span]
			The subspace of a vector space $V$ that is formed from all possible linear combinations of the vectors in a nonempty set $S$ is called the \emph{Span} of $S$, and we say that the vectors in $S$ \emph{span} that subspace.
		\end{defn}
	
		\begin{thm}
			If $S=\{\vec{v_1}, \vec{v_2}, \dots, \vec{v_r}\}$ and $S'=\{\vec{w_1}, \vec{w_2}, \dots, \vec{w_k}\}$ are nonempty sets of vectors in a vector space $V$, then $\verb|span|(S)=\verb|span|(S')$ iff each vector in $S$ is a linear combination of those in $S'$ and vice versa.
		\end{thm}

		\begin{defn}[Basis]
			If $V$ is any vector space and $S=\{\vec{v_1}, \vec{v_2}, \dots, \vec{v_r}\}$ is a finite set of linearly independent vectors in $V$ which spans $V$, then $S$ is called a \emph{basis} for $V$.
		\end{defn}
	
		\begin{thm}
			All bases for a finite-dimensional vector space have the same number of vectors.
		\end{thm}
		
		\begin{defn}[Dimension]
			The \emph{dimension} of a finite-dimensional vector space $V$, denoted by $\dim (V)$, is defined to be the number of vectors in a basis for $V$. In addition, the zero vector space is defined to have dimension zero.
		\end{defn}
	
		\begin{thm}
			If $S=\{\vec{v_1}, \vec{v_2}, \dots, \vec{v_r}\}$ is a basis for a vector space $V$, then every vector $\vec{v}$ in $V$ can be expressed in the form $\vec{v}=c_1\vec{v_1}+c_2\vec{v_2}+\dots+c_r\vec{v_r}$ in exactly one way.
		\end{thm}
	
		\begin{defn}[Coordinate]
			Let $S=\{\vec{v_1}, \vec{v_2}, \dots, \vec{v_r}\}$ be a basis for a vector space $V$ over the field $F$, and $\vec{v}=c_1\vec{v_1}+c_2\vec{v_2}+\dots+c_r\vec{v_r}$ is the expression for a vector $\vec{V}$ in terms of the basis $S$, then the scalars $c_1,c_2,\dots,c_n$ are called the \emph{coordinates} of $\vec{v}$ relative to the basis $S$. The vector $(c_1,c_2,\dots,c_n)$ in $F^n$ constructed from these coordinates is called the \emph{coordinate vector of $\vec{v}$ relative to $S$}, denoted by $(\vec{v})_S=(c_1,c_2,\dots,c_n)$.
		\end{defn}

\end{document}